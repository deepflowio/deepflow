# logfile path
log-file: /var/log/deepflow/server.log
# loglevel: "debug/info/warn/error"
log-level: info

controller:
  # controller http listenport
  listen-port: 20417

  # deepflow web service config
  df-web-service:
    enabled: false
    host: df-web
    port: 20825
    timeout: 30

  # mysql相关配置
  mysql:
    database: deepflow
    user-name: root
    user-password: deepflow
    host: mysql
    port: 30130
    timeout: 30

  # redis相关配置
  redis:
    enabled: true
    dimension_resource_database: 2
    password: deepflow
    host: redis
    port: 6379
    timeout: 30

  # clickhouse相关配置
  clickhouse:
    database: flow_tag
    user-name: default
    port: 9000
    # user-password:

  # roze
  roze:
    port: 30106
    timeout: 60

  # 规格相关定义
  spec:
    vtap_group_max: 1000
    vtap_max_per_group: 10000
    az_max_per_server: 10
    data_source_max: 10
    data_source_retention_time_max: 1000

  # monitor module config
  monitor:
    # controller/analyzer health_check interval, unit: s
    health_check_interval: 60
    # controller/analyzer health_check port, default: 30417
    health_check_port: 30417
    # 健康检查异常/控制器切换处理channel的长度
    health_check_handle_channel_len: 1000
    # License检查的时间间隔，单位: 秒
    license_check_interval: 60
    # vtap检查的时间间隔，单位: 秒
    vtap_check_interval: 60
    # warrant
    warrant:
      host: warrant
      port: 20413
      timeout: 30

  # manager module config
  manager:
    # 云平台增加/删除/配置变化检测的时间间隔，单位：秒
    cloud_config_check_interval: 60
    task:
      # recorder更新数据库的时间间隔，单位：秒
      resource_recorder_interval: 60
      cloud:
        # Kubernetes数据获取的时间间隔，单位：秒
        kubernetes_gather_interval: 60
        # 阿里公有云API获取区域列表时，需要指定一个区域
        aliyun_region_name: cn-beijing
      recorder:
        # recorder模块缓存自愈刷新时间间隔，单位：分钟
        cache_refresh_interval: 60
        # 软删除资源数据清理时间间隔，单位：小时
        # 此值应小于 soft_deleted_resource_expire_interval
        deleted_resource_clean_interval: 24
        # 软删除资源数据保留时间，单位：小时，默认：7 * 24
        deleted_resource_retention_time: 168

  trisolaris:
    tsdb_ip:
    chrony:
      host: 127.0.0.1
      port: 123
      timeout: 1

    trident-port: 20035
    trident-type-for-unkonw-vtap: 0

    platform-vips:
    #  - 55.11.135.18

    # master/slave 区域标识, 默认为主区域，部署时会自动修改
    node-type: master

    # grpc max message lenth default 100M
    grpc-max-message-length: 104857600

    # 区域服务域名前缀
    region-domain-prefix: ""

    # 采集器是否自动注册
    vtap-auto-register: True

    default-tap-mode:

  genesis:
    # 平台数据老化时间，单位：秒
    aging_time: 86400
    # 采集器接口数据老化时间，单位：秒
    vinterface_aging_time: 300
    # 无子网IP的最大掩码长度
    ipv4_cidr_max_mask: 24
    ipv6_cidr_max_mask: 64

    # 采集器上报数据处理的队列长度
    queue_length: 1000

    # 数据持久化检测间隔，单位：秒
    data_persistence_interval: 60

    # genesis的grpc通信端口
    grpc_server_port: 30035

    # 内网IP网段范围配置，配置的IP所在网络会被作为内网进行学习
    local_ip_ranges:
    # 排除IP范围
    exclude_ip_ranges:

querier:
  # querier http listenport
  listen-port: 20416

  # clickhouse相关配置
  clickhouse:
    database: flow_tag
    user: default
    host: clickhouse
    port: 9000
    timeout: 60

ingester:
  #ckdb-service-prefix: clickhouse
  #ckdb-service-port: 9000

  # local node ip, if not set will get from environment variable 'NODE_IP', dafault: ""
  #node-ip:

  ## trisolaris的ips, 默认值为空
  #controller-ips:
  #  - x.x.x.x

  ## controller listening port
  #controller-port: 20035

  ## es的相关的配置syslog写es
  #es-host-port:
  #  - 127.0.0.1:20042

  #es-auth:
  #  user:
  #  password:

  #ckdb-auth:
  #  user:
  #  password:

  #ckdb:
  #  primary: 127.0.0.1:9000
  #  secondary:          // 如果配置2个地址，xxx-replica-enabled 为false，则作为primary写入, xxx-replica-enabled 为true 作为replica写入

  ## ckdb若使用对象存储,需要设置将数据转移至对象存储
  #ckdb-s3:
  #  enabled: false  #是否使用了对象存储
  #  volume: vol_s3  #ckdb中对象存储的卷名
  #  ttl-times: 3    #对象存储中数据的存储时长是本地存储的几倍

  ## whether write stats data to influxdb
  #influxdb-writer-enabled: false

  ## 存储stats统计数据的influxdb地址
  #influxdb:
  #  host: influxdb
  #  port: 20044

  #metrics-replica-enabled: false
  #flowlog-replica-enabled: false

  ## 遥测数据写入配置
  #metrics-ck-writer:
  #  queue-count: 1      # 每个表并行写数量
  #  queue-size: 1000000 # 数据队列长度
  #  batch-size: 512000  # 多少行数据同时写入
  #  flush-timeout: 10   # 超时写入时间

  ## 流日志写入配置
  #flowlog-ck-writer:
  #  queue-count: 1      # 每个表并行写数量
  #  queue-size: 1000000 # 数据队列长度
  #  batch-size: 512000  # 多少行数据同时写入
  #  flush-timeout: 10   # 超时写入时间

  ## ext metrics写入配置
  #ext-metrics-ck-writer:
  #  queue-count: 1      # 每个表并行写数量
  #  queue-size: 100000  # 数据队列长度
  #  batch-size: 51200   # 多少行数据同时写入
  #  flush-timeout: 10   # 超时写入时间

  ## ext metrics数据的保留的时长(单位: 天)
  #ext-metrics-ttl: 7

  ## split prometheus metrics name lable to table name and metrics name, on the nth position of '_'
  # prometheus-separate-pos: 1

  ## 默认读超时，修改数据保留时长时使用
  #ck-read-timeout: 300

  ## clickhouse数据磁盘空间不足时，同时满足磁盘占用率>used-percent和磁盘空闲<free-space时，开始清理老数据
  #ck-disk-monitor:
  #  check-interval: 600 # 检查时间间隔(单位: 秒)
  #  used-percent: 90    # 磁盘占用率阈值
  #  free-space: 50      # 磁盘空闲阈值(单位: GB)

  ## stream,roze模块是否启用，默认启用, 若不启用(表示处于单独的控制器)
  #stream-roze-enabled: true

  ## syslog存储位置
  #syslog-directory: /var/log/deepflow-agent

  ## syslog是否写入elasticsearch，默认启用
  #es-syslog: true

  ## profiler
  #profiler: false

  ## maximum usage of cpu cores, 0 means no limit
  #max-cpus: 0

  ## udp socket receiver buffer: 64M
  #udp-read-buffer: 67108864

  ## tcp socket receiver buffer: 4M
  #tcp-read-buffer: 4194304

  ## ########################## droplet config ##########################################
  ## Rpc synchronization timeout default 8s
  #rpc-timeout: 8

  #adapter:
  #  ## cache size (#) for resuming the order of received trident traffic,
  #  ## default value is 64,
  #  ## 64 <= value <= 1024, value is 1024 when value > 1024
  #  ordering-cache-size: 64

  ## internal queues conf
  #queue:
  #  ## ----------- 并行度 -----------
  #  ## 传输网包的队列数量，也是网包处理（以网包作为输入）模块的并行度，默认为1，最大16
  #  packet-queue-count: 1
  #
  #  ## 传输网包的每个队列的长度，默认为65536
  #  packet-queue-size: 65536
  #
  #  ## syslog 接收队列长度, 默认为65536
  #  syslog-queue-size: 65536
  #
  #  ## statsd 接收队列长度, 默认为65536
  #  statsd-queue-size: 65536
  #
  #  ## 压缩包头接收队列长度, 默认为65536
  #  compressed-queue-size: 65536

  #labeler:
  #  ## whether to use first-path processing only
  #  fast-path-disable: false
  #
  #  ## size of policy fast-path map, and
  #  ## map-size-limit >= filter-queue-count*1024
  #  ## map-size-limit <= filter-queue-count*1048576
  #  map-size-limit: 1048576
  #  ## 值越大策略Firstpath表内存使用越少性能越低，取值范围为[1,16]，其他非法值使用默认值8
  #  level: 0

  #pcap:
  #  ## 计算TCP/IP checksum，默认不计算
  #  tcpip-checksum: false
  #
  #  ## 单次写入文件的块大小，默认64KB
  #  block-size-kb: 64
  #
  #  ## 同时在写的最大pcap文件数，默认5000
  #  max-concurrent-files: 5000
  #
  #  ## 每个pcap文件的最大大小，默认25MB，但是1秒内即使超过该值也不会切分文件
  #  max-file-size-mb: 25
  #
  #  ## 所有pcap文件的最大总大小，默认100GB
  #  max-directory-size-gb: 100
  #
  #  ## 磁盘剩余空间不足该数值时进行删除，默认10GB
  #  disk-free-space-margin-gb: 10
  #
  #  ## 每个pcap文件的最大时间，默认300秒
  #  max-file-period-second: 300
  #
  #  ## pcap文件存储的文件夹
  #  file-directory: /var/lib/pcap

  ## ########################### roze config #############################################

  ## 是否不写入秒级数据: 默认: false(写入)
  #disable-second-write: false

  ## 是否不写秒级数据的replica: 默认: true(不写)
  #disable-second-write-replica: true

  ## parallelism of unmarshall, defaults to 4
  #unmarshall-queue-count: 4

  ## size of unmarshall queue, defaults to 10240
  #unmarshall-queue-size: 10240

  ## ########################## stream config ############################################
  ## 用来保证全集群流日志_id的唯一性
  #shard-id: 0

  ## writer all queue limit max size
  #throttle: 50000

  ## 分别控制l4流日志, l7流日志，默认值为0，表示使用throttle的设置值.若非0，则使用设置值
  #l4-throttle: 0
  #l7-throttle: 0

  #decoder-queue-count: 2
  #decoder-queue-size: 10000

  #flow-log-disabled:
  #  l4: false
  #  l7: false
  #  http: false
  #  dns: false
  #  mysql: false
  #  redis: false
  #  dubbo: false
  #  kafka: false
  #  mqtt: false
